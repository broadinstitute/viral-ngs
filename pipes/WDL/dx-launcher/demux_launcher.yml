# DNAnexus applet to build with dx-yml-build which can be found here:
# https://gist.githubusercontent.com/mlin/3cce81f54a640c3f62a2725acbc98283/raw/e071dfe1989c31f6267334106115620770e6d21c/dx-yml-build
# To build, save this file as dxapp.yml and run that script alongside.
name: demux_launcher
title: demux_launcher
dxapi: 1.0.0
version: 0.0.1
description: Launches demux/demux-plus workflow on each lane of a sequencing run, given the incremental uploader sentinel record.
inputSpec:
- name: upload_sentinel_record
  class: record
  type: "UploadSentinel"
  help: Sentinel record from incremental upload tool. The RunInfo.xml and run tarballs must also reside in the current project.
- name: demux_workflow_id
  class: string
  help: DNAnexus ID (workflow-xxxx) of the demux/demux-plus workflow to launch on each lane of the run. The workflow and all its parts and dependencies must reside in the current project.
  default: DEFAULT_DEMUX_WORKFLOW_ID
- name: consolidate_run_tarballs_applet_id
  class: string
  help: DNAnexus ID (applet-xxxx) of the consolidate_run_tarballs applet to use when needed; must reside in the current project.
  default: DEFAULT_CONSOLIDATE_RUN_TARBALLS_APPLET_ID
- name: folder
  class: string
  default: /
  help: Output folder in the root project. For this applet, the --destination should be set to / and this input should be used to control the output folder.
- name: sequencing_center
  class: string
  optional: true
  help: Optional- the name of the sequencing center to be included in the demultiplexed output (bam files). Please avoid spaces and special characters.
- name: api_token
  class: file
  optional: true
  help: Optional- to launch each lane demux as a top-level analysis instead of a sub-job, so that the analyses succeed or fail independently, provide a text file containing a DNAnexus API token with at least CONTRIBUTE access to the current project. Protect this file by isolating it in a separate project, viewable only by users who will invoke this launcher.
outputSpec:
- name: run_tarball
  class: file
  help: If the run was uploaded in multiple partial tarballs, they're consolidated and output here. Otherwise the uploaded tarball is echoed.
- name: demux_outputs_all
  class: array:file
  help: All files output from the demux/demux-plus analyses
access:
  network: ["*"]
runSpec:
  systemRequirements:
    main:
      instanceType: mem1_ssd1_x2
    launch_demux:
      instanceType: mem1_ssd1_x2
  distribution: Ubuntu
  release: "16.04"
  execDepends:
    - name: pigz
    - name: libxml2-utils
  interpreter: bash
  code: |
    #!/bin/bash

    main() {
      set -ex -o pipefail

      # Download the RunInfo.xml file
      runInfo_file_id=$(dx get_details "$upload_sentinel_record" | jq .runinfo_file_id -r)
      dx cat $runInfo_file_id > RunInfo.xml

      if [ -n "$api_token" ]; then
        dx download -o api_token "$api_token"
      fi

      # Parse the lane count & run ID from RunInfo.xml file
      lane_count=$(xmllint --xpath "string(//Run/FlowcellLayout/@LaneCount)" RunInfo.xml)
      if [ -z "$lane_count" ]; then
          dx-jobutil-report-error "Could not parse LaneCount from RunInfo.xml. Please check RunInfo.xml is properly formatted"
      fi

      surface_count=$(xmllint --xpath "string(//Run/FlowcellLayout/@SurfaceCount)" RunInfo.xml)
      if [ -z "$surface_count" ]; then
          dx-jobutil-report-error "Could not parse SurfaceCount from RunInfo.xml. Please check RunInfo.xml is properly formatted"
      fi

      swath_count=$(xmllint --xpath "string(//Run/FlowcellLayout/@SwathCount)" RunInfo.xml)
      if [ -z "$swath_count" ]; then
          dx-jobutil-report-error "Could not parse SwathCount from RunInfo.xml. Please check RunInfo.xml is properly formatted"
      fi

      tile_count=$(xmllint --xpath "string(//Run/FlowcellLayout/@TileCount)" RunInfo.xml)
      if [ -z "$tile_count" ]; then
          dx-jobutil-report-error "Could not parse TileCount from RunInfo.xml. Please check RunInfo.xml is properly formatted"
      fi
      
      run_id=$(xmllint --xpath "string(//Run/@Id)" RunInfo.xml)
      if [ -z "$run_id" ]; then
          dx-jobutil-report-error "Could not parse Run@Id from RunInfo.xml. Please check RunInfo.xml is properly formatted"
      fi

      # total data size more roughly tracks total tile count
      total_tile_count=$((lane_count*surface_count*swath_count*tile_count))

      demux_instance_type="mem1_ssd1_x4"
      demux_threads=$(echo "$demux_instance_type" | cut -dx -f2)
      min_base_quality=25
      max_reads_in_ram_per_tile=1000000
      max_records_in_ram=2000000
      if [ "$total_tile_count" -le 50 ]; then 
          tar_consolidation_instance_size="mem1_ssd1_x4"
          demux_instance_type="mem1_ssd1_x4"
          demux_threads=$(echo "$demux_instance_type" | cut -dx -f2)
          echo "Detected $total_tile_count tiles, interpreting as MiSeq run, executing on a $demux_instance_type machine."
      elif [ "$total_tile_count" -le 150 ]; then
          tar_consolidation_instance_size="mem1_ssd2_x4"
          demux_instance_type="mem1_ssd2_x4"
          demux_threads=$(echo "$demux_instance_type" | cut -dx -f2)
          echo "Detected $total_tile_count tiles, interpreting as HiSeq2k run, executing on a $demux_instance_type machine."
      elif [ "$total_tile_count" -le 288 ]; then
          # increase the number of reads in ram per-tile for NextSeq, since the tiles are larger
          # without this setting, reads will spill to disk and may read the limit
          # on the number of files that can be opened
          max_reads_in_ram_per_tile=1500000
          max_records_in_ram=2000000
          echo "Detected $total_tile_count tiles, interpreting as NextSeq (mid-output) run."
      elif [ "$total_tile_count" -le 864 ]; then
          # increase the number of reads in ram per-tile for NextSeq, since the tiles are larger
          # without this setting, reads will spill to disk and may read the limit
          # on the number of files that can be opened
          max_reads_in_ram_per_tile=200000 # reduce the number of reads per tile since the NovaSeq has so many
          max_records_in_ram=1500000
          echo "Detected $total_tile_count tiles, interpreting as NextSeq (high-output) run."
      elif [ "$total_tile_count" -le 896 ]; then
          tar_consolidation_instance_size="mem1_ssd1_x32"
          demux_instance_type="mem1_ssd1_x32"
          demux_threads=$(echo "$demux_instance_type" | cut -dx -f2)
          echo "Detected $total_tile_count tiles, interpreting as HiSeq4k run, executing on a $demux_instance_type machine."
      elif [ "$total_tile_count" -le 1408 ]; then
          tar_consolidation_instance_size="mem1_ssd2_x36"
          demux_instance_type="mem1_ssd2_x36"
          min_base_quality=20
          max_reads_in_ram_per_tile=750000
          demux_threads=20 # with NovaSeq-size output, OOM errors can sporadically occur with higher thread counts
          echo "Detected $total_tile_count tiles, interpreting as NovaSeq run, executing on a $demux_instance_type machine."
          echo "  **Note: Q20 threshold used since NovaSeq with RTA3 writes only four Q-score values: 2, 12, 23, and 37.**"
          echo "    See: https://www.illumina.com/content/dam/illumina-marketing/documents/products/appnotes/novaseq-hiseq-q30-app-note-770-2017-010.pdf"
      elif [ "$total_tile_count" -gt 1408 ]; then
          tar_consolidation_instance_size="mem1_ssd2_x36"
          demux_instance_type="mem1_ssd2_x36"
          demux_threads=$(echo "$demux_instance_type" | cut -dx -f2)
          echo "Tile count: $total_tile_count tiles, (unknown instrument type), executing on a $demux_instance_type machine."
      fi
      echo "For detailed information on instance types, see:"
      echo "   https://wiki.dnanexus.com/api-specification-v1.0.0/instance-types#Full-list-of-AWS-instance-types"

      run_tarball=""
      dx get_details "$upload_sentinel_record" | jq -r .tar_file_ids[] > tar_file_ids
      if [ "$(cat tar_file_ids | wc -l)" -gt 1 ]; then
        # if there are multiple run tarballs, launch a subjob to consolidate them
        runcmd="dx run $consolidate_run_tarballs_applet_id --instance-type=$tar_consolidation_instance_size -i upload_sentinel_record=$(dx-jobutil-parse-link "$upload_sentinel_record") -i run_id=$run_id --folder $folder -y --brief"
        echo "$runcmd"
        set +x
        if [ -n "$api_token" ]; then
          # add API token to run command without copying it into the job log
          runcmd="unset DX_JOB_ID; $runcmd --auth-token $(cat api_token | tr -d '\n')"
        fi
        subjob=$(bash -e -o pipefail -c "$runcmd")
        set -x
        run_tarball="$subjob:consolidated_run_tarball"
      else
        run_tarball=$(cat tar_file_ids | tr -d '\n')
      fi
      dx-jobutil-add-output run_tarball $run_tarball

      if [ -n "$demux_workflow_id" ]; then
        # launch the demux workflow on each lane
        analyses=()
        output_project=$DX_WORKSPACE_ID
        if [ -n "$sequencing_center" ]; then
          sequencing_center_input="-i illumina_demux.sequencingCenter=$sequencing_center"
        else
          sequencing_center_input=""
        fi
        for i in $(seq "$lane_count"); do
          folder2=$(printf "%s/%s/reads/L%d" "$folder" "$run_id" $i)
          runcmd="dx run $demux_workflow_id -i stage-1.flowcell_tgz=$run_tarball -i illumina_demux.lane=$i -i illumina_demux.maxReadsInRamPerTile=$max_reads_in_ram_per_tile -i illumina_demux.maxRecordsInRam=$max_records_in_ram -i illumina_demux.minimumBaseQuality=$min_base_quality -i illumina_demux.threads=$demux_threads $sequencing_center_input --folder $folder2 --instance-type illumina_demux=$demux_instance_type --name demux:$run_id:L$i -y --brief"
          echo "$runcmd"
          set +x
          if [ -n "$api_token" ]; then
            # add API token to run command without copying it into the job log
            runcmd="unset DX_JOB_ID; $runcmd --auth-token $(cat api_token | tr -d '\n')"
            output_project=$DX_PROJECT_CONTEXT_ID
          fi
          analysis=$(bash -e -o pipefail -c "$runcmd")
          set -x
          analyses+=($analysis)
        done

        # schedule a subjob when all the demux analyses complete, to propagate all their
        # output files to the output of this job.
        subjob=$(dx-jobutil-new-job propagate_outputs -i output_project=$output_project -i folder="$folder" -i run_id="$run_id" --depends-on ${analyses[@]})
        echo $subjob
        dx-jobutil-add-output demux_outputs_all $subjob:demux_outputs
      fi
    }

    propagate_outputs() {
      set -ex -o pipefail
      dx find data --brief --class file --project $output_project --folder "$folder/$run_id/reads" | cut -d ':' -f2 |  xargs -t -i dx-jobutil-add-output demux_outputs --class array:file "{}"
    }
