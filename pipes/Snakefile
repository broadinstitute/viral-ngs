"""
    This is a basic framework for processing of of viral genomes, currently
    tailored for EBOV. Some generalization work needed to expand this
    to generic viral genomes with an arbitrary number of segments/chromosomes.

    Make copies of this Snakefile and config.yaml to your analysis directory and
    customize as needed.
"""

__author__ = 'Daniel Park <dpark@broadinstitute.org>'

import os, yaml

configfile: "config.yaml"
pipesDir = os.path.join(os.path.expanduser(config['bin_dir']), 'pipes')
rulesDir = os.path.join(pipesDir, 'rules')

include: os.path.join(rulesDir, 'common.rules')
config = process_cfg_includes(config, std_include=os.path.join(pipesDir,'config.yaml'))
set_env_vars()

include: os.path.join(rulesDir, 'demux.rules')
include: os.path.join(rulesDir, 'hs_deplete.rules')
include: os.path.join(rulesDir, 'assembly.rules')
include: os.path.join(rulesDir, 'metagenomics.rules')
include: os.path.join(rulesDir, 'interhost.rules')
include: os.path.join(rulesDir, 'ncbi.rules')
include: os.path.join(rulesDir, 'intrahost.rules')
include: os.path.join(rulesDir, 'reports.rules')

samples_assembly = list(read_samples_file(config["samples_assembly"]))
samples_metagenomics = list(read_samples_file(config["samples_metagenomics"]))

all_inputs = [
    # create final assemblies for all samples
    expand("{data_dir}/{subdir}/{sample}.fasta",
           data_dir=config["data_dir"], subdir=config["subdirs"]["assembly"],
           sample=samples_assembly),
    # create BAMs of aligned reads to own consensus and to common ref
    expand("{data_dir}/{subdir}/{sample}.bam",
           data_dir=config["data_dir"], subdir=config["subdirs"]["align_self"],
           sample=samples_assembly),
    # intrahost variant calling
    config["data_dir"]+'/'+config["subdirs"]["intrahost"] +'/isnvs.vcf.gz',
    # create summary reports
    expand("{reports_dir}/summary.fastqc.{adjective}.txt",
           reports_dir=config["reports_dir"],
           adjective=['raw', 'cleaned', 'taxfilt', 'align_to_self'])
]

if config.get('spikeins_db'):
    all_inputs.append(config["reports_dir"]+'/summary.spike_count.txt')
if config.get('kraken_db'):
    all_inputs.extend(
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.raw.kraken.report"), sample=samples_metagenomics))

rule all:
    input: all_inputs
    params: LSF="-N"
    run:
            if "job_profiler" in config:
                print("running report on all job runs")
                shell("{config[job_profiler]} {config[log_dir]} {config[reports_dir]}/summary.job_stats.txt")
            print("echo all done!")

rule clean:
    params: LSF="-N"
    shell: "rm -rf {config[tmp_dir]}/* .snakemake/tmp.*"
