import os.path

samples = list(read_samples_file(config.get("samples_metagenomics")))

rule all_metagenomics:
    input:
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.raw.{method}.report"), sample=samples, method=['kraken', 'rna_bwa', 'rna_bwa.nodupes']),
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.raw.{method}.krona.html"), sample=samples, method=['kraken', 'rna_bwa', 'rna_bwa_nodupes'])
    params: LSF='-N'


rule all_metagenomics_host_depleted:
    input:
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.cleaned.{method}.report"), sample=samples, method=['kraken', 'rna_bwa']),
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.cleaned.{method}.krona.html"), sample=samples, method=['kraken', 'rna_bwa'])
    params: LSF='-N'

rule all_kraken:
    input:
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.raw.kraken.report"), sample=samples),
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.raw.kraken.krona.html"), sample=samples)
    params: LSF='-N'

rule all_kraken_host_depleted:
    input:
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.cleaned.kraken.report"), sample=samples),
        expand(os.path.join(config["data_dir"], config["subdirs"]["metagenomics"],
                    "{sample}.cleaned.kraken.krona.html"), sample=samples)
    params: LSF='-N'

method_props = {
    'diamond': {
        'reads_ext': 'diamond.lca.gz',
    },
    'kraken': {
        'reads_ext': 'kraken.reads.gz',
    },
    'rna_bwa': {
        'reads_ext': 'rna_bwa.lca.gz',
    },
    'rna_bwa_nodupes': {
        'reads_ext': 'rna_bwa.lca_nodupes.gz',
    }
}

taxfiles = [
                'gi_taxid_nucl.dmp',
                'gi_taxid_prot.dmp',
                'names.dmp',
                'nodes.dmp'
            ]

            # 'merged.dmp',
            # 'gi_taxid.readme',
            # 'gi_taxid_nucl_diff.dmp',
            # ,'taxcat_readme.txt','Cowner_dump.txt',
            # 'taxcat.zip','division.dmp','coll_dump.txt',
            # 'gi_taxid_prot_diff.dmp','gi_taxid.bin','gi_taxid_nucl_diff.zip',
            # 'taxcat.tar','Ccode_dump.txt','citations.dmp','gc.prt','taxdump.tar','gencode.dmp',
            # 'gi_taxid_prot.zip','taxdmp.zip','Icode_dump.txt','readme.txt','taxdump_readme.txt',,'taxdump.tar.Z',
            # 'categories.dmp','delnodes.dmp','gi_taxid_prot_diff.zip',
            # ,'taxcat.tar.Z','gi_taxid_prot.dmp','gi_taxid_nucl.zip'] # 'accession2taxid',

krakenfiles = ["database.idx","database.jdb","database.kdb","gi2seqid.map","lca.complete","seqid2taxid.map"]

rna_bwa_ext = ['sa', 'bwt', 'amb', 'sa', 'ann', 'pac'] #, 'fa']

rule diamond:
    input: 
        bam         = os.path.join(config["data_dir"], config["subdirs"]["per_sample"], "{sample}.{adjective}.bam"),
        diamond_db  = objectify_remote(expand("{path_prefix}.{ext}", path_prefix=config["diamond_db"], ext=["dmnd"])),
        taxonomy_db = objectify_remote(expand("{path_prefix}/{taxfile}", path_prefix=config["taxonomy_db"], taxfile=taxfiles))
    output: 
        report = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.diamond.report"),
        lca    = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.diamond.lca.gz")
    resources: 
        threads=int(config.get("number_of_threads", 1)),
        mem=120
    params: 
        threads=str(config.get("number_of_threads", 1)),
        UGER=config.get('UGER_queues', {}).get('long', '-q long')
    run:
        diamond_db_prefix = os.path.dirname(strip_protocol(config["diamond_db"], relative=True))
        taxonomy_db_prefix = strip_protocol(config["taxonomy_db"], relative=True)
        shell("{config[bin_dir]}/metagenomics.py diamond {input.bam} "+diamond_db_prefix+" "+taxonomy_db_prefix+" {output.report} --outLca {output.lca} --numThreads {params.threads}")
        

rule kraken:
    input: 
        bam         = os.path.join(config["data_dir"], config["subdirs"]["per_sample"], "{sample}.{adjective}.bam"),
        kraken_db   = objectify_remote(expand("{path_prefix}/{krakenfile}", path_prefix=config["kraken_db"], krakenfile=krakenfiles)),
        taxonomy_db = objectify_remote(expand("{path_prefix}/taxonomy/{taxfile}", path_prefix=config["kraken_db"], taxfile=taxfiles))
    output: 
        report = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.kraken.report"),
        reads  = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.kraken.reads.gz")
    resources: 
        threads=int(config.get("number_of_threads", 1)),
        mem=120
    params: 
        threads=str(config.get("number_of_threads", 1)),
        UGER=config.get('UGER_queues', {}).get('long', '-q long')
    run:
        kraken_db_prefix = strip_protocol(config["kraken_db"], relative=True)
        shell("{config[bin_dir]}/metagenomics.py kraken {input.bam} "+kraken_db_prefix+" --outReads {output.reads} --outReport {output.report} --numThreads {params.threads}")

rule align_rna:
    input: 
        bam = os.path.join(config["data_dir"], config["subdirs"]["per_sample"], "{sample}.{adjective}.bam"),
        rna_bwa_db = objectify_remote(expand("{path_prefix}.{ext}", path_prefix=config["align_rna_db"], ext=rna_bwa_ext)),
        taxonomy_db = objectify_remote(expand("{path_prefix}/{taxfile}", path_prefix=config["taxonomy_db"], taxfile=taxfiles))
    output: 
        report         = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.rna_bwa.report"),
        nodupes_report = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.rna_bwa.nodupes.report"),
        bam            = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.rna_bwa.bam"),
        lca            = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.rna_bwa.lca.gz"),
        nodupes_lca    = os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.rna_bwa.lca_nodupes.gz")
    resources: 
        threads=int(config.get("number_of_threads", 1)),
        mem=36
    params: 
        threads=str(config.get("number_of_threads", 1)),
        UGER=config.get('UGER_queues', {}).get('long', '-q long')
    run:
        rna_bwa_path_prefix = strip_protocol(config["align_rna_db"], relative=True)
        taxonomy_db_prefix = strip_protocol(config["taxonomy_db"], relative=True)
        shell("{config[bin_dir]}/metagenomics.py align_rna {input.bam} "+rna_bwa_path_prefix+" "+taxonomy_db_prefix+" {output.nodupes_report} --dupeReport {output.report} --outBam {output.bam} --outLca {output.nodupes_lca} --dupeLca {output.lca} --JVMmemory {resources.mem}g --numThreads {params.threads}")

rule krona_import_taxonomy:
    input: 
        tsv = lambda wildcards: os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], \
           ".".join([wildcards.sample, wildcards.adjective, method_props[wildcards.method]['reads_ext']])),
        krona_db = objectify_remote(expand("{path_prefix}/{kronafile}", path_prefix=config["krona_db"], kronafile=["taxonomy.tab", "gi_taxid.dat"]))
    output: 
        os.path.join(config["data_dir"], config["subdirs"]["metagenomics"], "{sample}.{adjective,raw|cleaned}.{method,kraken|diamond|rna_bwa|rna_bwa_nodupes}.krona.html")
    resources: 
        mem=32
    run:
        krona_db_prefix = strip_protocol(config["krona_db"], relative=True)
        shell("{config[bin_dir]}/metagenomics.py krona {input.tsv} "+krona_db_prefix+" {output} --noRank")
