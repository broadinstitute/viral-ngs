
import os, os.path, sys, collections
# imports needed for download_file() and webfile_readlines()
import re
# since py3 split up urllib
try:
    from urllib.request import urlopen
except ImportError:
    from urllib2 import urlopen

# Ensure that Snakemake rules can import viral-ngs python code
sys.path.append(os.path.realpath(os.path.join(os.path.expanduser(config['bin_dir']))))
import util, util.misc, util.file

shell.executable("/bin/bash")

# Load config params from any included config files, including the standard default one; load any params
# specified under legacy names.
config = util.misc.load_config(config, 
                               std_includes=[os.path.join(os.path.expanduser(config['bin_dir']), 
                                                          'pipes', 'config.yaml')],
                               param_renamings={})

def set_env_vars():
    import os
    for k,v in config.get('env_vars', {}).items():
        if k not in os.environ:
            os.environ[k] = v

def read_tab_file(fname):
    with util.file.compressed_open(fname, 'rt') as inf:
        header = [item.strip() for item in inf.readline().strip().rstrip('\n').split('\t')]
        for line in inf:
            if len(line.strip())==0:
                continue
            row = [item.strip() for item in line.rstrip('\n').split('\t')]
            if len(row) > len(header):
                # truncate the row to the header length, and only include extra items if they are not spaces 
                # (takes care of the case where the user may enter an extra space at the end of a row)
                row = row[:len(header)] + [item for item in row[len(header):] if len(item)]
            assert len(header) == len(row)
            yield dict(zip(header, row))

def read_samples_file(fname, number_of_chromosomes=1, append_chrom_num=False):
    if fname==None:
        return []
    with util.file.compressed_open(fname, 'rt') as inf:
        for line in inf:
            if len(line.strip())==0:
                continue
            if not append_chrom_num:
                yield line.strip()
            else:
                line = line.strip()
                for i in range(1, number_of_chromosomes+1):
                    yield line+"-{idx}".format(idx=str(i))

def read_accessions_file(fname):
    if fname==None:
        return []
    with util.file.compressed_open(fname, 'rt') as inf:
        for line in inf:
            if len(line.strip())==0:
                continue
            yield line.strip()

def download_file(uriToGet, dest, destFileName=None):
    destDir = os.path.realpath(os.path.expanduser(dest))

    req = urlopen(uriToGet)

    if not destFileName:
        m = re.search('filename="(?P<filename>.+)"', req.info()['Content-Disposition'])

        if m:
            destFileName = m.group("filename")
        else:
            destFileName = "file"

    destPath = os.path.join(destDir, destFileName)

    with open(destPath, "wb") as outf:
        while True:
           chunk = req.read(1024)
           if not chunk: break
           outf.write(chunk)

    return destPath

def webfile_readlines(uriToGet):

    for line in urlopen(uriToGet):#.readlines():
        cleanedLine = line.decode("utf-8").strip()
        if len(cleanedLine) > 0:
            yield cleanedLine

def strip_protocol(uri, relative=False):

    def parse_address(text):
        return re.search(r"^(?P<protocol>[a-zA-Z0-9]+\://){1}(?P<path_remainder>.*)$", text)

    if parse_address(uri):
        if not relative:
            return parse_address(uri).group("path_remainder")
        else:
            return os.path.join(".", parse_address(uri).group("path_remainder"))
    else:
        return uri


import botocore.session

def objectify_remote(file_address, *args, **kwargs):
    if file_address is None:
        raise IOError("%s is None" % file_address)

    # if this is a string, make it a list, otherwise use it as an iterable
    file_list = file_address if util.misc.is_nonstr_iterable(file_address) else [file_address]

    for index, uri in enumerate(file_list):
        if uri.lower().startswith('s3://'):
            import snakemake.remote.S3

            # if botocore cannot find credentials, try connecting unsigned.
            # This should work for anonymous S3 resources
            # and testing on Travis where no credentials are set.
            # This can be removed if/when Snakemake does the same check itself
            if botocore.session.get_session().get_credentials():
                remote_provider = snakemake.remote.S3.RemoteProvider()
            else:
                remote_provider = snakemake.remote.S3.RemoteProvider(config=botocore.client.Config(signature_version=botocore.UNSIGNED))

            file_list[index] = remote_provider.remote(uri, *args, **kwargs)
        elif uri.lower().startswith('gs://'):
            import snakemake.remote.GS
            remote_provider = snakemake.remote.GS.RemoteProvider()
            file_list[index] = remote_provider.remote(uri, *args, **kwargs)
        elif uri.lower().startswith('sftp://'):
            import snakemake.remote.SFTP
            remote_provider = snakemake.remote.SFTP.RemoteProvider()
            file_list[index] = remote_provider.remote(uri, *args, **kwargs)

    return file_list
