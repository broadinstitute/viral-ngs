
import os, os.path, sys
# imports needed for download_file() and webfile_readlines()
import re
# since py3 split up urllib
try:
    from urllib.request import urlopen
except ImportError:
    from urllib2 import urlopen

# Ensure that Snakemake rules can import viral-ngs python code
sys.path.append(os.path.realpath(os.path.join(os.path.expanduser(config['bin_dir']))))
import util, util.misc

shell.executable("/bin/bash")

# Load config params from any included config files, including the standard default one; load any params
# specified under legacy names.
config = util.misc.load_config(config, 
                               std_includes=[os.path.join(os.path.expanduser(config['bin_dir']), 
                                                          'pipes', 'config.yaml')],
                               param_renamings={})

def set_env_vars():
    import os
    for k,v in config.get('env_vars', {}).items():
        if k not in os.environ:
            os.environ[k] = v

def read_tab_file(fname):
    with open(fname, 'rt') as inf:
        header = [item.strip() for item in inf.readline().strip().rstrip('\n').split('\t')]
        for line in inf:
            row = [item.strip() for item in line.rstrip('\n').split('\t')]
            if len(row) > len(header):
                # truncate the row to the header length, and only include extra items if they are not spaces 
                # (takes care of the case where the user may enter an extra space at the end of a row)
                row = row[:len(header)] + [item for item in row[len(header):] if len(item)]
            assert len(header) == len(row)
            yield dict(zip(header, row))

def read_samples_file(fname, number_of_chromosomes=1, append_chrom_num=False):
    if fname==None:
        return []
    with open(fname, 'rt') as inf:
        for line in inf:
            if not append_chrom_num:
                yield line.strip()
            else:
                line = line.strip()
                for i in range(1, number_of_chromosomes+1):
                    yield line+"-{idx}".format(idx=str(i))

def read_accessions_file(fname):
    if fname==None:
        return []
    with open(fname, 'rt') as inf:
        for line in inf:
            yield line.strip()

def download_file(uriToGet, dest, destFileName=None):
    destDir = os.path.realpath(os.path.expanduser(dest))

    req = urlopen(uriToGet)

    if not destFileName:
        m = re.search('filename="(?P<filename>.+)"', req.info()['Content-Disposition'])

        if m:
            destFileName = m.group("filename")
        else:
            destFileName = "file"

    destPath = os.path.join(destDir, destFileName)

    with open(destPath, "wb") as outf:
        while True:
           chunk = req.read(1024)
           if not chunk: break
           outf.write(chunk)

    return destPath

def webfile_readlines(uriToGet):

    for line in urlopen(uriToGet):#.readlines():
        cleanedLine = line.decode("utf-8").strip()
        if len(cleanedLine) > 0:
            yield cleanedLine
