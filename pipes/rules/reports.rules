"""
    These rules generate reports and metrics on reads and assemblies.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, gzip, shutil

all_reports = [
    config["reports_dir"]+'/summary.fastqc.raw.txt',
    config["reports_dir"]+'/summary.fastqc.cleaned.txt',
    config["reports_dir"]+'/summary.fastqc.taxfilt.txt',
    config["reports_dir"]+'/summary.fastqc.align_to_self.txt'
]

if config.get("spikeins_db"):
    all_reports.append(config["reports_dir"]+'/summary.spike_count.txt')

rule all_reports:
    input: all_reports
    params: LSF="-N"

rule all_ref_guided_fastqc:
    input: config["reports_dir"]+'/summary.fastqc.align_to_ref.txt'

#-----------FASTQC---------------------

def fastqc_report_inputs(wildcards):
    if wildcards.adjective == 'raw':
        return os.path.join(config["data_dir"], config["subdirs"]["source"],
                            wildcards.sample + '.bam')
    elif wildcards.adjective in ['cleaned', 'taxfilt']:
        return os.path.join(config["data_dir"], config["subdirs"]["depletion"],
                            wildcards.sample + '.' + wildcards.adjective + '.bam')
    elif wildcards.adjective == 'align_to_self':
        return os.path.join(config["data_dir"], config["subdirs"]["align_self"],
                            wildcards.sample + '.bam')
    elif wildcards.adjective == 'align_to_ref':
        return os.path.join(config["data_dir"], config["subdirs"]["align_ref"],
                            wildcards.sample + '.realigned.only_aligned.bam')
    else:
        return "unreachable-{}-{}".format(wildcards.sample, wildcards.adjective)

rule fastqc_report:
    input:  fastqc_report_inputs
    output: config["reports_dir"]+'/fastqc/{sample}/{adjective}'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="{sample}-{adjective}"
    run:
            makedirs(config["reports_dir"])
            shutil.rmtree(output[0], ignore_errors=True)
            makedirs(os.path.join(config["reports_dir"], 'fastqc'))
            shell("fastqc -f bam {input} -o {config[reports_dir]}/fastqc/{wildcards.sample}")
            fastqc_out = os.path.basename(input[0])[:-len('.bam')] + '_fastqc'
            shell("unzip {config[reports_dir]}/fastqc/{wildcards.sample}/" + fastqc_out + ".zip -d {config[reports_dir]}/fastqc/{wildcards.sample}")
            shutil.move(os.path.join(config["reports_dir"], 'fastqc', wildcards.sample, fastqc_out),
                        os.path.join(config["reports_dir"], 'fastqc', wildcards.sample, wildcards.adjective))
            os.unlink(os.path.join(config["reports_dir"], 'fastqc',
                                   wildcards.sample, fastqc_out + '.zip'))
            os.unlink(os.path.join(config["reports_dir"], 'fastqc',
                                   wildcards.sample, fastqc_out + '.html'))

rule consolidate_fastqc_on_all_runs:
    input:
            expand("{{dir}}/fastqc/{sample}/{{adjective}}",
                sample=read_samples_file(config["samples_per_run"]))
    output: '{dir}/summary.fastqc.{adjective,raw|cleaned|taxfilt}.txt'
    params: logid="all"
    shell:  "{config[bin_dir]}/reports.py consolidate_fastqc {input} {output}"

rule consolidate_fastqc_on_all_assemblies:
    input:
            expand("{{dir}}/fastqc/{sample}/{{adjective}}",
                sample=read_samples_file(config["samples_assembly"]))
    output: '{dir}/summary.fastqc.{adjective,align_to_self|align_to_ref}.txt'
    params: logid="all"
    shell:  "{config[bin_dir]}/reports.py consolidate_fastqc {input} {output}"

#-----------SPIKE-INS------------------

if config.get("spikeins_db"):
    rule spikein_report:
        input:  config["data_dir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.cleaned.bam'
        output: config["reports_dir"]+'/spike_count/{sample}.spike_count.txt'
        resources: mem=3
        params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
                UGER=config.get('UGER_queues', {}).get('short', '-q short'),
                logid="{sample}",
                spikeins_db=config["spikeins_db"]
        run:
                makedirs(os.path.join(config["reports_dir"], 'spike_count'))
                makedirs(os.path.join(config["tmp_dir"], config["subdirs"]["depletion"]))
                shell("{config[bin_dir]}/read_utils.py bwamem_idxstats {input} {params.spikeins_db} --outStats {output}")

    rule consolidate_spike_count:
        input:  expand("{{dir}}/spike_count/{sample}.spike_count.txt", \
                    sample=read_samples_file(config["samples_per_run"]))
        output: '{dir}/summary.spike_count.txt'
        params: logid="all"
        shell:  "{config[bin_dir]}/reports.py consolidate_spike_count {wildcards.dir}/spike_count {output}"
