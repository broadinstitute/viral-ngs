"""
    This is a basic framework for assembly of viral genomes, currently
    tailored for EBOV. Some generalization work needed to expand this
    to generic viral genomes with an arbitrary number of segments/chromosomes.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time, shutil


rule all_assemble:
    input:
        # create final assemblies for all samples
        expand("{data_dir}/{subdir}/{sample}.fasta",
            data_dir=config["data_dir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
        # create BAMs of aligned reads to own consensus
        expand("{data_dir}/{subdir}/{sample}.bam",
            data_dir=config["data_dir"], subdir=config["subdirs"]["align_self"],
            sample=read_samples_file(config["samples_assembly"]))
    params: LSF="-N"

rule all_assemble_failures:
    input:
        expand("{data_dir}/{subdir}/{sample}.fasta",
            data_dir=config["data_dir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config.get("samples_assembly_failures")))
    params: LSF="-N"



rule assemble_trinity:
    ''' This step runs the Trinity assembler.
        First trim reads with trimmomatic, rmdup with prinseq,
        and random subsample to no more than 100k reads.
    '''
    input:
        bam    = config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.taxfilt.bam',
        clipDb = objectify_remote(config["trim_clip_db"])
    output:
        fasta = config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity.fasta',
        subsamp_bam = config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.subsamp.bam'
    resources:
        mem     = 7,
        threads = int(config.get("number_of_threads", 1))
    params: 
        LSF         = config.get('LSF_queues', {}).get('short', '-W 4:00'),
        UGER        = config.get('UGER_queues', {}).get('short', '-l h_rt=04:00:00'),
        n_reads     = str(config["trinity_n_reads"]),
        logid       = "{sample}",
    run:
        makedirs(expand("{dir}/{subdir}",
            dir=[config["data_dir"],config["tmp_dir"]],
            subdir=config["subdirs"]["assembly"]))
        shell("{config[bin_dir]}/assembly.py assemble_trinity {input.bam} {input.clipDb} {output.fasta} --n_reads={params.n_reads} --outReads {output.subsamp_bam} --threads {resources.threads} --JVMmemory 5g")

rule assemble_spades:
    ''' This step runs the SPAdes assembler.
    '''
    input:  taxfilt_reads=config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.taxfilt.bam',
            clipDb = objectify_remote(config["trim_clip_db"])
    output: contigs_spades=config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-spades.fasta'
    resources: 
            mem=12,
            threads=int(config.get("number_of_threads", 1))
    params: n_reads=str(config["spades_n_reads"]),
            logid="{sample}"
    run:
            shell("{config[bin_dir]}/assembly.py assemble_spades {input.taxfilt_reads} {input.clipDb} {output.contigs_spades} --nReads {params.n_reads} --threads {resources.threads} --memLimitGb {resources.mem}")


rule assemble_trinity_spades:
    ''' This step runs the Trinity assembler then the SPAdes assembler.
    '''
    input:  taxfilt_reads=config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.taxfilt.bam',
            clipDb = objectify_remote(config["trim_clip_db"]),
            contigs_trinity=config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity.fasta'
    output: contigs_trinity_spades=config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity-spades.fasta'
    resources: 
            mem=12,
            threads=int(config.get("number_of_threads", 1))
    params: n_reads=str(config["spades_n_reads"]),
            logid="{sample}"
    run:
            shell("{config[bin_dir]}/assembly.py assemble_spades {input.taxfilt_reads} {input.clipDb} {output.contigs_trinity_spades} --contigsUntrusted {input.contigs_trinity} --nReads {params.n_reads} --threads {resources.threads} --memLimitGb {resources.mem}")

            
rule orient_and_impute:
    ''' This step cleans up the Trinity assembly with a known reference genome.
        order_and_orient (MUMmer): take the de novo assembly,
            align them to the known reference genome, switch it to the same
            strand as the reference, and produce chromosome-level assemblies
            (with runs of N's in between the de novo contigs).
        filter_short_seqs: Fail on assemblies that come out to
            < 15kb or < 95% unambiguous.
        impute_from_reference: trim off anything at the end that exceeds
            the length of the known reference assembly.  We also replace all
            Ns and everything within 55bp of the chromosome ends with the
            reference sequence.  This is clearly incorrect consensus sequence,
            but it allows downstream steps to map reads in parts of the genome
            that would otherwise be Ns, and we will correct all of the inferred
            positions with two steps of read-based refinement (below), and
            revert positions back to Ns where read support is lacking.  The
            de novo step is still important because it allows for significant
            structural / indel changes (or significant substitution distances)
            which will be captured in this output.
    '''
    input:  
        fasta      = config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-'+config["assembly_assembler"]+'.fasta',
        cleaned_reads = config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam',
        refsel_genomes = objectify_remote(expand( '{refDir}/'+'{ref_name}.fasta', refDir=config["refsel_ref_db_dir"], ref_name="refsel" ))
    output: 
        fasta = config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.fasta'
    resources: 
        mem = 12,
        threads = int(config.get("number_of_threads", 1))
    params: 
        LSF  = config.get('LSF_queues', {}).get('short', '-W 4:00'),
        UGER = config.get('UGER_queues', {}).get('short', '-l h_rt=04:00:00'),
        # length should be defined as a fraction/percentage cutoff, relative to 
        # reference length for a given sequence. float is in the config.yaml file
        length           = str(config["assembly_min_length_fraction_of_reference"]),
        min_unambig      = str(config["assembly_min_unambig"]),
        renamed_prefix   = "",
        replace_length   = str(config.get("assembly_replace_length", 55)),
        logid            = "{sample}",
        scaffold_ref = config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-scaffold_ref.fasta',
        scaffolded_fasta = config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-scaffolded.fasta',
        gapfilled_fasta=config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-gapfilled.fasta',
        alternate_fasta  = config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-alternate_sequences.fasta'
    run:
        ono_extra = []
        if config.get("assembly_nucmer_max_gap"):
            ono_extra.extend(["--maxgap", str(config["assembly_nucmer_max_gap"])])
        if config.get("assembly_nucmer_min_match"):
            ono_extra.extend(["--minmatch", str(config["assembly_nucmer_min_match"])])
        if config.get("assembly_nucmer_min_cluster"):
            ono_extra.extend(["--mincluster", str(config["assembly_nucmer_min_cluster"])])
        if config.get("scaffold_min_pct_contig_aligned"):
            ono_extra.extend(["--min_pct_contig_aligned", str(config["scaffold_min_pct_contig_aligned"])])
        ono_extra = " ".join(ono_extra)
        n_genome_segments = len(config["accessions_for_ref_genome_build"])
        shell("{config[bin_dir]}/assembly.py order_and_orient {input.fasta} {input.refsel_genomes} {params.scaffolded_fasta} {ono_extra} --outAlternateContigs {params.alternate_fasta} --nGenomeSegments {n_genome_segments} --outReference {params.scaffold_ref} --threads {resources.threads}")
        shell("{config[bin_dir]}/assembly.py gapfill_gap2seq {params.scaffolded_fasta} {input.cleaned_reads} {params.gapfilled_fasta} --memLimitGb {resources[mem]} --maskErrors --randomSeed {config[random_seed]}")
        shell("{config[bin_dir]}/assembly.py impute_from_reference {params.gapfilled_fasta} {params.scaffold_ref} {output.fasta} --newName {params.renamed_prefix}{wildcards.sample} --replaceLength {params.replace_length} --minLengthFraction {params.length} --minUnambig {params.min_unambig} --index")

rule refine_assembly_1:
    ''' This a first pass refinement step where we take the scaffolded assembly,
        align all reads back to it, and modify the assembly to the majority
        allele at each position based on read pileups.
        This step now considers both SNPs as well as indels called by GATK
        and will correct the consensus based on GATK calls.
        Reads are aligned with Novoalign with permissive mapping thresholds,
        then PCR duplicates are removed with Picard (in order to debias the
        allele counts in the pileups), and realigned with GATK's
        IndelRealigner (in order to call indels).
        Output FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  
        config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.fasta',
        config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: 
        config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
        config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.vcf.gz'
    resources: 
        mem     = 7,
        threads = int(config.get("number_of_threads", 1))
    params: 
        LSF               = config.get('LSF_queues', {}).get('short', '-W 4:00'),
        UGER              = config.get('UGER_queues', {}).get('short', '-l h_rt=04:00:00'),
        logid             = "{sample}",
        novoalign_options = config.get("refine_assembly_1_novoalign_params", "-r Random -l 30 -g 40 -x 20 -t 502"),
        min_coverage      = "2"
    shell:  "{config[bin_dir]}/assembly.py refine_assembly {input} {output[0]} --outVcf {output[1]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --threads {resources.threads}"

rule refine_assembly_2:
    ''' This a second pass refinement step very similar to the first.
        The only differences are that Novoalign mapping parameters are
        more conservative and the input consensus sequence has already
        been refined once. We also require higher minimum read coverage
        (3 instead of 2) in order to call a non-ambiguous base.
        The output of this step is the final assembly for this sample.
        Final FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  
        config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
        config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: 
        config["data_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta',
        config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.vcf.gz'
    resources: 
        mem     = 7,
        threads = int(config.get("number_of_threads", 1))
    params: 
        LSF               = config.get('LSF_queues', {}).get('short', '-W 4:00'),
        UGER              = config.get('UGER_queues', {}).get('short', '-l h_rt=04:00:00'),
        logid             = "{sample}",
        novoalign_options = config.get("refine_assembly_2_novoalign_params", "-r Random -l 40 -g 40 -x 20 -t 100"),
        min_coverage      = "3"
    shell:  
        "{config[bin_dir]}/assembly.py refine_assembly {input} {output[0]} --outVcf {output[1]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --threads {resources.threads}"

rule map_reads_to_self:
    ''' After the final assembly is produced, we also produce BAM files with all reads
        mapped back to its own consensus.  Outputs several BAM files, sorted and indexed:
            {sample}.bam        - all raw reads aligned to self
            {sample}.mapped.bam - only mapped reads, duplicates removed by Picard,
                                  realigned with GATK IndelRealigner
    '''
    input:  
        config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam',
        config["data_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
    output: 
        config["data_dir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.bam',
        config["data_dir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.mapped.bam'
    resources: 
        mem     = 4,
        threads = int(config.get("number_of_threads", 1))
    params: 
        LSF             = config.get('LSF_queues', {}).get('short', '-W 4:00'),
        UGER            = config.get('UGER_queues', {}).get('short', '-l h_rt=04:00:00'),
        logid           = "{sample}",
        aligner_options = config.get('map_reads_to_self_novoalign_params', "-r Random -l 40 -g 40 -x 20 -t 100 -k") if config.get('map_reads_to_self_aligner', "novoalign")=="novoalign" else "",
        aligner         = config.get('map_reads_to_self_aligner', "novoalign")
    run:
        makedirs([os.path.join(config["data_dir"], config["subdirs"]["align_self"]),
            os.path.join(config["reports_dir"], "assembly")])
        shell("{config[bin_dir]}/read_utils.py align_and_fix {input} --outBamAll {output[0]} --outBamFiltered {output[1]} --aligner novoalign --aligner_options '{params.aligner_options}' --threads {resources.threads}")
