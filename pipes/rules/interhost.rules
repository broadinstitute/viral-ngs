"""
    This is a basic framework for alignment and SNP calling in viral genomes,
    currently tailored for EBOV.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time


def merge_vcfs(inFiles, refFasta, outFile):
    inFilesString = ' '.join(['--variant '+i for i in inFiles])
    shell("java -Xmx2g -jar /humgen/gsa-hpprojects/GATK/bin/GenomeAnalysisTK-3.3-0-g37228af/GenomeAnalysisTK.jar" \
        + " -T CombineVariants -R {refFasta} {inFilesString} -o {outFile}" \
        + " --genotypemergeoption UNIQUIFY")

def update_timestamps(files):
    ''' this dumb function exists because sometimes the different nodes on the
        cluster have out-of-sync system clocks and snakemake fails if the mtime of
        any input file is more recent than the mtimes of the output files
    '''
    for f in files:
        if os.path.isfile(f) and os.path.getmtime(f) > time.time():
            print("input file %s is more recent than present, resetting its modification time to present" % f)
            os.utime(f)

rule all_ref_guided:
    input:
            os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.fasta'),
            os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.vcf.gz'),
            expand("{dir}/bamstats/{sample}.{adjective}.txt",
                dir=config["reportsDir"],
                adjective=['raw','cleaned',
                    'ref_align', 'ref_mapped', 'ref_rmdup', 'ref_realigned'],
                sample=read_samples_file(config["samples_per_run"])),
            config["reportsDir"]+'/summary.coverage_ref.txt.gz'

rule ref_guided_consensus:
    input:  config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.raw.bam'
    output: config["dataDir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.realigned.bam',
            config["dataDir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.vcf.gz',
            config["dataDir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.fasta'
    resources: mem=4
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="{sample}",
            refGenome=config["ref_genome"],
            novoalign_options="-r Random -l 30 -g 40 -x 20 -t 502",
            min_coverage="3"
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["dataDir"]],
                subdir=[config["subdirs"]["align_ref"], config["subdirs"]["assembly"]]))
            shell("{config[binDir]}/assembly.py refine_assembly {params.refGenome} {input} {output[2]} --outBam {output[0]} --outVcf {output[1]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --keep_all_reads --chr_names {wildcards.sample}")

rule ref_guided_diversity:
    input:  
            expand("{dataDir}/{subdir}/{sample}.{ext}",
                dataDir=config["dataDir"],
                subdir=config["subdirs"]["align_ref"],
                ext = ['fasta', 'vcf.gz'],
                sample=read_samples_file(config["samples_per_run"]))
    output: os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.fasta'),
            os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.vcf.gz')
    resources: mem=8
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="all",
            refGenome=config["ref_genome"],
            inFastas = expand("{dataDir}/{subdir}/{sample}.fasta",
                dataDir=config["dataDir"], subdir=config["subdirs"]["align_ref"],
                sample=read_samples_file(config["samples_per_run"])),
            inVcfs = expand("{dataDir}/{subdir}/{sample}.vcf.gz",
                dataDir=config["dataDir"], subdir=config["subdirs"]["align_ref"],
                sample=read_samples_file(config["samples_per_run"]))
    run:
            update_timestamps(input)
            shell("cat {params.inFastas} > {output[0]}")
            merge_vcfs(params.inVcfs, params.refGenome, output[1])






'''
rule multi_align_mafft:
    input:  config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
    output: config["dataDir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.pruned.phy'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="all",
            tmpf_mafft=config["tmpDir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.mafft.fasta',
            log_trimal=config["tmpDir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.log.trimal.html'
    # TODO: replace with python wrapper
    run:
            makedirs(os.path.join(config["dataDir"], config["subdirs"]["interhost"]),
                os.path.join(config["tmpDir"], config["subdirs"]["interhost"]))
            shell("/idi/sabeti-scratch/kandersen/bin/mafft/core/mafft --localpair --maxiterate 1000 --reorder --ep 0.123 --preservecase --thread 4 {input} > {params.tmpf_mafft}")
            shell("/idi/sabeti-scratch/kandersen/bin/trimal/trimal -phylip -automated1 -in {params.tmpf_mafft} -out {output} -htmlout {params.log_trimal} -colnumbering")
            update_timestamps(input)


# Make sure all file-names are unique when cut down to 10 characters - e.g. if analysing Lassa 'LASV-' identifier needs to be removed from the input sequence file.


#-------- SEQUENCE ALIGNMENT --------#

#-------- TREE BUILDING USING MAXIMUM LIKELIHOOD - RAXML --------#
# CREATE TREE
for sequences in
do
for directory in
do
for substitution_model in GTRGAMMA
do
for bootstraps in 500
do
bsub -sp 100 -R "rusage[mem=2]" -n 2 -R "span[hosts=1]" -W 4:00 -q hour -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.tr1 "/idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-PTHREADS-SSE3 -f d -T 2 -p 123421 -m $substitution_model -N 20 -n $sequences.tree1 -w $directory/_trees/ -s $directory/_msa/$sequences.pruned.phy"
bsub -sp 90 -n 4 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.tr2 "/idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-PTHREADS-SSE3 -f d -T 4 -p 12438 -m $substitution_model -b 12438 -N $bootstraps -k -n $sequences.tree2 -w $directory/_trees/ -s $directory/_msa/$sequences.pruned.phy && /idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-SSE3 -T 1 -m $substitution_model -n $sequences.tree3 -f b -t $directory/_trees/RAxML_bestTree.$sequences.tree1 -z $directory/_trees/RAxML_bootstrap.$sequences.tree2 -w $directory/_trees/ && mv $directory/_trees/RAxML_bipartitions.$sequences.tree3 $directory/_trees/$sequences.raxml.tree"
done
done
done
done

#-------- CREATE TREES USING PHYML --------#
# CREATE TREE
for sequences in
do
for directory in
do
for substitution_model in GTR # HKY85, JC69, K80, F81, F84, TN93
do
for bootstraps in 500
do
bsub -n 1 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.pm "/idi/sabeti-scratch/kandersen/bin/phyml/PhyML-3.1_linux64 -i $directory/_msa/$sequences.pruned.phy -d nt -b $bootstraps -m $substitution_model --pinv 0 --nclasses 4 -s BEST --rand_start --n_rand_starts 10 --r_seed 1553 -f m --no_memory_check && mv $directory/_msa/$sequences.pruned.phy_phyml* $directory/_trees/ && /idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-SSE3 -f b -t $directory/_trees/$sequences.pruned.phy_phyml_tree.txt -z $directory/_trees/$sequences.pruned.phy_phyml_boot_trees.txt -m GTRGAMMA -s $directory/_msa/$sequences.pruned.phy -n $sequences.phyml.tree -w $directory/_trees/ && mv $directory/_trees/RAxML_bipartitions.$sequences.phyml.tree $directory/_trees/$sequences.phyml.tree"
done
done
done
done

#-------- CREATE TREES USING MR BAYES --------#
# OUTPUT NEXUS FILE
for sequences in
do
for directory in
do
bsub -R "rusage[mem=2]" -n 1 -R "span[hosts=1]" -W 4:00 -q hour -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.pr "/idi/sabeti-scratch/kandersen/bin/trimal/trimal -automated1 -in $directory/_msa/$sequences.pruned.phy -nexus -out $directory/_msa/$sequences.pruned.nex"
done
done

# RUN MR BAYES
for sequences in
do
for directory in
do
bsub -R "rusage[mem=2]" -n 1 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.mb "cp $directory/_msa/$sequences.pruned.nex $directory/_trees/mr-bayes/$sequences.nex && /idi/sabeti-scratch/kandersen/bin/mrbayes/run_mrbayes.sh $directory/_trees/mr-bayes/$sequences.nex"
done
done



#----do snp calling w/rachel's script & snpEff
'''






